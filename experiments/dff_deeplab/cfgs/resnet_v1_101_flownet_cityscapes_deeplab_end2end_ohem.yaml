---
MXNET_VERSION: "mxnet"
output_path: "./output/dff_deeplab/cityscapes"
symbol: resnet_v1_101_flownet_deeplab
gpus: '0,1,2,3'
SCALES:
- 1024
- 2048
default:
  frequent: 100
  kvstore: device
network:
  pretrained: "./model/rfcn_dff_flownet_vid"
  pretrained_flow: "./model/deeplab_cityscapes"
  pretrained_epoch: 0
  PIXEL_MEANS:
  - 103.06
  - 115.90
  - 123.15
  IMAGE_STRIDE: 0
  FIXED_PARAMS:
  - conv1
  - bn_conv1
  - res2
  - bn2
  - gamma
  - beta
  FIXED_PARAMS_SHARED:
  - conv1
  - bn_conv1
  - res2
  - bn2
  - res3
  - bn3
  - res4
  - bn4
  - gamma
  - beta
dataset:
  NUM_CLASSES: 19
  dataset: CityScape
  dataset_path: "./data/cityscapes"
  image_set: leftImg8bit_train
  root_path: "./data"
  test_image_set: leftImg8bit_val
TRAIN:
  warmup: true
  warmup_lr: 0.00005
  # typically we will use 4000 warmup step for single GPU
  warmup_step: 1000
  begin_epoch: 0
  end_epoch: 53
  lr: 0.0005
  lr_step: '40.336'
  model_prefix: "dff_deeplab_vid"
  # whether flip image
  FLIP: false
  # size of images for each device
  BATCH_IMAGES: 1
  # e2e changes behavior of anchor loader and metric
  END2END: true
  # wheter crop image during training
  ENABLE_CROP: False
  # scale of cropped image during training
  CROP_HEIGHT: 768
  CROP_WIDTH: 1024
  # whether resume training
  RESUME: false
  # whether shuffle image
  SHUFFLE: true
TEST:
  # size of images for each device
  BATCH_IMAGES: 1
  test_epoch: 53
